{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+JO67JdQ8ymAy9rVLl+G5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirmalghimire/DDP_Achievement-Gap/blob/main/Covid_impact_2022_OECD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o50a4PNokZMv",
        "outputId": "7ff33a98-f880-4841-a302-ab26f00c2c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyreadr\n",
            "  Downloading pyreadr-0.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: missingno in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.14.1)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->shap) (0.43.0)\n",
            "Downloading pyreadr-0.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.7/411.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyreadr\n",
            "Successfully installed pyreadr-0.5.3\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install pyreadr shap matplotlib seaborn scikit-learn pandas numpy missingno\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import pyreadr\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from tabulate import tabulate\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the data from your local machine to Google Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "uM75ZCJ9n8dz",
        "outputId": "dcc4f722-407d-44df-8332-465d4df9b13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f6a54412-fffa-484a-976f-6a3ab967fdac\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f6a54412-fffa-484a-976f-6a3ab967fdac\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving merged_school_data_2022.RData to merged_school_data_2022.RData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the RData file\n",
        "result = pyreadr.read_r('merged_school_data_2022.RData')\n",
        "df = result[list(result.keys())[0]]  # Get the first element in the dictionary"
      ],
      "metadata": {
        "id": "SCha3LVyoJpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic information about the dataset\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(\"Column names:\", df.columns.tolist())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99R6-isjoN3J",
        "outputId": "37ac20d9-2afd-4cfd-ae3c-c654ad6c08fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (21629, 18)\n",
            "Column names: ['CNT', 'CNTRYID', 'CNTSCHID', 'OECD', 'PRIVATESCH', 'SCHLTYPE', 'PROBSCRI', 'SCPREPAP', 'SCPREPBP', 'DIGPREP', 'DaysClosed_COVID', 'Remote_Teaching', 'Self_Study', 'Class_Cancelled', 'W_FSTUWT_SCH_N', 'sch_reading_score', 'sch_math_score', 'sch_science_score']\n",
            "   CNT  CNTRYID  CNTSCHID  OECD PRIVATESCH SCHLTYPE  PROBSCRI  SCPREPAP  \\\n",
            "0  ALB      8.0  800001.0   0.0     Public        3    0.7965    0.8462   \n",
            "1  ALB      8.0  800002.0   0.0     Public        3   -0.5687    0.8462   \n",
            "2  ALB      8.0  800003.0   0.0    Private        1    0.1896   -0.8711   \n",
            "3  ALB      8.0  800004.0   0.0     Public        3       NaN       NaN   \n",
            "4  ALB      8.0  800005.0   0.0     Public        3    0.6649    0.8462   \n",
            "\n",
            "   SCPREPBP  DIGPREP  DaysClosed_COVID  Remote_Teaching  Self_Study  \\\n",
            "0   -0.8314   0.5908              90.0              5.0         5.0   \n",
            "1   -0.8314  -0.3475              70.0              5.0         1.0   \n",
            "2   -0.8314   0.4409             115.0              5.0         5.0   \n",
            "3       NaN  -0.7414               0.0              NaN         NaN   \n",
            "4   -0.8314  -0.0102               2.0              5.0         2.0   \n",
            "\n",
            "   Class_Cancelled  W_FSTUWT_SCH_N  sch_reading_score  sch_math_score  \\\n",
            "0              5.0            41.0         373.560106      392.053710   \n",
            "1              1.0            36.0         350.785750      362.305774   \n",
            "2              5.0             3.0         286.955100      321.824700   \n",
            "3              NaN            39.0         337.623681      327.827862   \n",
            "4              1.0             5.0         459.560728      452.295826   \n",
            "\n",
            "   sch_science_score  \n",
            "0         413.353654  \n",
            "1         380.047975  \n",
            "2         326.194200  \n",
            "3         335.143531  \n",
            "4         440.181744  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target variable\n",
        "features = [\n",
        "    'SCHLTYPE', 'OECD', 'DIGPREP', 'PROBSCRI', 'SCPREPAP', 'SCPREPBP',\n",
        "    'DaysClosed_COVID', 'Remote_Teaching', 'Self_Study', 'Class_Cancelled'\n",
        "]\n",
        "target = 'sch_reading_score'\n",
        "\n",
        "# Create a new dataframe with only the features and target\n",
        "data = df[features + [target]].copy()"
      ],
      "metadata": {
        "id": "MDl8TeaG05xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing data\n",
        "missing_data = data.isnull().sum()\n",
        "print(\"\\nMissing data per column:\")\n",
        "print(missing_data)\n",
        "missing_percent = (missing_data / len(data)) * 100\n",
        "print(\"\\nMissing data percentage:\")\n",
        "print(missing_percent)\n",
        "\n",
        "# Check the distribution of categorical variables\n",
        "print(\"\\nSCHLTYPE value counts:\")\n",
        "print(data['SCHLTYPE'].value_counts(dropna=False))\n",
        "print(\"\\nOECD value counts:\")\n",
        "print(data['OECD'].value_counts(dropna=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4OgNsmMERTI",
        "outputId": "9b9ffcb7-a7b8-4e18-ed96-c5ceb4786544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing data per column:\n",
            "SCHLTYPE              1622\n",
            "OECD                     0\n",
            "DIGPREP               4050\n",
            "PROBSCRI              6380\n",
            "SCPREPAP             10725\n",
            "SCPREPBP              5776\n",
            "DaysClosed_COVID      3139\n",
            "Remote_Teaching       6142\n",
            "Self_Study            6423\n",
            "Class_Cancelled       6539\n",
            "sch_reading_score        0\n",
            "dtype: int64\n",
            "\n",
            "Missing data percentage:\n",
            "SCHLTYPE              7.499191\n",
            "OECD                  0.000000\n",
            "DIGPREP              18.724860\n",
            "PROBSCRI             29.497434\n",
            "SCPREPAP             49.586204\n",
            "SCPREPBP             26.704887\n",
            "DaysClosed_COVID     14.512922\n",
            "Remote_Teaching      28.397060\n",
            "Self_Study           29.696241\n",
            "Class_Cancelled      30.232558\n",
            "sch_reading_score     0.000000\n",
            "dtype: float64\n",
            "\n",
            "SCHLTYPE value counts:\n",
            "SCHLTYPE\n",
            "3      16017\n",
            "1       2277\n",
            "2       1713\n",
            "NaN     1622\n",
            "Name: count, dtype: int64\n",
            "\n",
            "OECD value counts:\n",
            "OECD\n",
            "1.0    11108\n",
            "0.0    10521\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =====================\n",
        "# PART 1: OECD vs. NON-OECD ANALYSIS\n",
        "# ====================="
      ],
      "metadata": {
        "id": "C688jlIu2MxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n\" + \"=\"*50)\n",
        "print(\"PART 1: OECD vs. NON-OECD ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def analyze_oecd_subset(data, oecd_status, subset_name):\n",
        "    print(f\"\\n\\n===== ANALYZING {subset_name} =====\")\n",
        "\n",
        "    # Filter data for the specific OECD status\n",
        "    subset_data = data[data['OECD'] == oecd_status].copy()\n",
        "    print(f\"Number of schools in {subset_name}: {len(subset_data)}\")\n",
        "\n",
        "    # Handle missing data in target variable\n",
        "    subset_data = subset_data.dropna(subset=[target])\n",
        "    print(f\"Schools with valid target in {subset_name}: {len(subset_data)}\")\n",
        "\n",
        "    if len(subset_data) < 100:\n",
        "        print(f\"Not enough data for {subset_name} analysis.\")\n",
        "        return None\n",
        "\n",
        "    # Remove OECD from features since we're analyzing by OECD status\n",
        "    subset_features = [f for f in features if f != 'OECD']\n",
        "\n",
        "    # Define categorical and numerical features\n",
        "    categorical_features = ['SCHLTYPE']\n",
        "    numerical_features = [f for f in subset_features if f != 'SCHLTYPE']\n",
        "\n",
        "    # Prepare X and y\n",
        "    X = subset_data[subset_features]\n",
        "    y = subset_data[target]\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create preprocessing pipeline with imputation\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', Pipeline(steps=[\n",
        "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
        "            ]), categorical_features),\n",
        "            ('num', IterativeImputer(random_state=42), numerical_features)\n",
        "        ])\n",
        "\n",
        "    # Create a pipeline with preprocessing and random forest\n",
        "    rf_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=500, max_depth=15, random_state=42, n_jobs=-1))\n",
        "    ])\n",
        "\n",
        "    # Fit the model\n",
        "    print(f\"Training Random Forest model for {subset_name}...\")\n",
        "    try:\n",
        "        rf_pipeline.fit(X_train, y_train)\n",
        "        print(f\"Model training completed for {subset_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model training: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    # Get feature names after one-hot encoding\n",
        "    try:\n",
        "        feature_names = []\n",
        "        # Get one-hot encoded feature names for categorical features\n",
        "        ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
        "        feature_names.extend(ohe.get_feature_names_out(categorical_features))\n",
        "        # Add numerical feature names\n",
        "        feature_names.extend(numerical_features)\n",
        "        print(f\"Feature names extracted: {len(feature_names)} features\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting feature names: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    # Make predictions and evaluate the model\n",
        "    try:\n",
        "        y_pred = rf_pipeline.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "\n",
        "        print(f\"{subset_name} - Mean Squared Error: {mse:.2f}\")\n",
        "        print(f\"{subset_name} - R² Score: {r2:.4f}\")\n",
        "        print(f\"{subset_name} - RMSE: {rmse:.2f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model evaluation: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    # Create model performance table\n",
        "    model_performance = {\n",
        "        'Model': f\"Random Forest ({subset_name})\",\n",
        "        'Mean Squared Error': f'{mse:.2f}',\n",
        "        'R² Score': f'{r2:.4f}',\n",
        "        'RMSE': f'{rmse:.2f}',\n",
        "        'Sample Size': len(X_test)\n",
        "    }\n",
        "\n",
        "    # Print the table\n",
        "    print(f\"\\n{subset_name} Model Performance:\")\n",
        "    print(tabulate([model_performance], headers='keys', tablefmt='simple'))\n",
        "\n",
        "    # Save performance to file\n",
        "    with open(f'{subset_name.replace(\" \", \"_\")}_performance.csv', 'w') as f:\n",
        "        f.write(tabulate([model_performance], headers='keys', tablefmt='csv'))\n",
        "\n",
        "    # Get the RandomForest model from the pipeline\n",
        "    rf_model = rf_pipeline.named_steps['regressor']\n",
        "\n",
        "    # Get feature importances\n",
        "    try:\n",
        "        importances = rf_model.feature_importances_\n",
        "        print(f\"Feature importances extracted: {len(importances)} values\")\n",
        "\n",
        "        # Sort feature importances\n",
        "        indices = np.argsort(importances)[::-1]\n",
        "\n",
        "        # Create a feature importance table\n",
        "        fi_table = []\n",
        "        cumulative = 0\n",
        "\n",
        "        for i in indices:\n",
        "            clean_name = feature_names[i].replace('_', ' ').capitalize()\n",
        "            if clean_name.startswith('SCHLTYPE'):\n",
        "                clean_name = clean_name.replace('SCHLTYPE_', 'School Type: ')\n",
        "\n",
        "            cumulative += importances[i]\n",
        "            fi_table.append({\n",
        "                'Feature': clean_name,\n",
        "                'Importance': f'{importances[i]:.4f}',\n",
        "                'Cumulative %': f'{cumulative*100:.2f}%'\n",
        "            })\n",
        "\n",
        "        # Print the feature importance table\n",
        "        print(f\"\\n{subset_name} Feature Importance:\")\n",
        "        print(tabulate(fi_table, headers='keys', tablefmt='simple'))\n",
        "\n",
        "        # Save feature importance to file\n",
        "        with open(f'{subset_name.replace(\" \", \"_\")}_feature_importance.csv', 'w') as f:\n",
        "            f.write(tabulate(fi_table, headers='keys', tablefmt='csv'))\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating feature importance: {str(e)}\")\n",
        "        fi_table = []\n",
        "\n",
        "    # SHAP analysis\n",
        "    shap_table = []\n",
        "    try:\n",
        "        print(f\"\\nCalculating SHAP values for {subset_name}...\")\n",
        "\n",
        "        # Transform the test data\n",
        "        X_test_transformed = preprocessor.transform(X_test)\n",
        "\n",
        "        # Use a sample if the test set is large\n",
        "        max_shap_samples = 2000\n",
        "        if len(X_test) > max_shap_samples:\n",
        "            print(f\"Sampling {max_shap_samples} out of {len(X_test)} for SHAP analysis\")\n",
        "            sample_indices = np.random.choice(len(X_test), max_shap_samples, replace=False)\n",
        "            X_test_sample = X_test_transformed[sample_indices]\n",
        "        else:\n",
        "            X_test_sample = X_test_transformed\n",
        "\n",
        "        # Create an explainer\n",
        "        explainer = shap.TreeExplainer(rf_model)\n",
        "\n",
        "        # Calculate SHAP values\n",
        "        shap_values = explainer.shap_values(X_test_sample)\n",
        "        print(f\"SHAP values calculated with shape: {shap_values.shape}\")\n",
        "\n",
        "        # Create a SHAP values table\n",
        "        mean_abs_shap = np.abs(shap_values).mean(0)\n",
        "        top_indices = np.argsort(mean_abs_shap)[::-1]\n",
        "\n",
        "        for i in top_indices:\n",
        "            clean_name = feature_names[i].replace('_', ' ').capitalize()\n",
        "            if clean_name.startswith('SCHLTYPE'):\n",
        "                clean_name = clean_name.replace('SCHLTYPE_', 'School Type: ')\n",
        "\n",
        "            shap_table.append({\n",
        "                'Feature': clean_name,\n",
        "                'Mean |SHAP Value|': f'{mean_abs_shap[i]:.4f}',\n",
        "                'Min SHAP': f'{np.min(shap_values, axis=0)[i]:.4f}',\n",
        "                'Max SHAP': f'{np.max(shap_values, axis=0)[i]:.4f}'\n",
        "            })\n",
        "\n",
        "        # Print the SHAP values table\n",
        "        print(f\"\\n{subset_name} SHAP Values:\")\n",
        "        print(tabulate(shap_table[:10], headers='keys', tablefmt='simple'))\n",
        "\n",
        "        # Save SHAP values to file\n",
        "        with open(f'{subset_name.replace(\" \", \"_\")}_shap_values.csv', 'w') as f:\n",
        "            f.write(tabulate(shap_table[:10], headers='keys', tablefmt='csv'))\n",
        "    except Exception as e:\n",
        "        print(f\"Error during SHAP analysis: {str(e)}\")\n",
        "\n",
        "    # Return the results\n",
        "    return {\n",
        "        'subset_name': subset_name,\n",
        "        'model_performance': model_performance,\n",
        "        'feature_importance': fi_table,\n",
        "        'shap_values': shap_table[:10]\n",
        "    }\n",
        "\n",
        "# Run OECD status analyses\n",
        "print(\"\\nRunning analysis for OECD countries...\")\n",
        "oecd_results = analyze_oecd_subset(data, 1, \"OECD Countries\")\n",
        "\n",
        "print(\"\\nRunning analysis for non-OECD countries...\")\n",
        "non_oecd_results = analyze_oecd_subset(data, 0, \"Non-OECD Countries\")\n",
        "\n",
        "# Compare OECD and non-OECD results\n",
        "if oecd_results and non_oecd_results:\n",
        "    # Compare model performance\n",
        "    oecd_performance = [\n",
        "        {'Subset': 'OECD Countries',\n",
        "         'MSE': oecd_results['model_performance']['Mean Squared Error'],\n",
        "         'R²': oecd_results['model_performance']['R² Score'],\n",
        "         'RMSE': oecd_results['model_performance']['RMSE'],\n",
        "         'Sample Size': oecd_results['model_performance']['Sample Size']},\n",
        "        {'Subset': 'Non-OECD Countries',\n",
        "         'MSE': non_oecd_results['model_performance']['Mean Squared Error'],\n",
        "         'R²': non_oecd_results['model_performance']['R² Score'],\n",
        "         'RMSE': non_oecd_results['model_performance']['RMSE'],\n",
        "         'Sample Size': non_oecd_results['model_performance']['Sample Size']}\n",
        "    ]\n",
        "\n",
        "    print(\"\\n\\nComparison of OECD vs. Non-OECD Performance:\")\n",
        "    print(tabulate(oecd_performance, headers='keys', tablefmt='simple'))\n",
        "\n",
        "    # Save comparison to file\n",
        "    with open('oecd_performance_comparison.csv', 'w') as f:\n",
        "        f.write(tabulate(oecd_performance, headers='keys', tablefmt='csv'))\n",
        "\n",
        "    # Compare top 5 features\n",
        "    top_features_comparison = []\n",
        "\n",
        "    # Get top 5 features for OECD\n",
        "    oecd_top = [f['Feature'] for f in oecd_results['feature_importance'][:5]]\n",
        "    non_oecd_top = [f['Feature'] for f in non_oecd_results['feature_importance'][:5]]\n",
        "\n",
        "    top_features_comparison.append({\n",
        "        'Subset': 'OECD Countries',\n",
        "        'Top Feature 1': oecd_top[0],\n",
        "        'Top Feature 2': oecd_top[1],\n",
        "        'Top Feature 3': oecd_top[2],\n",
        "        'Top Feature 4': oecd_top[3],\n",
        "        'Top Feature 5': oecd_top[4]\n",
        "    })\n",
        "\n",
        "    top_features_comparison.append({\n",
        "        'Subset': 'Non-OECD Countries',\n",
        "        'Top Feature 1': non_oecd_top[0],\n",
        "        'Top Feature 2': non_oecd_top[1],\n",
        "        'Top Feature 3': non_oecd_top[2],\n",
        "        'Top Feature 4': non_oecd_top[3],\n",
        "        'Top Feature 5': non_oecd_top[4]\n",
        "    })\n",
        "\n",
        "    print(\"\\n\\nTop Features Comparison (OECD vs. Non-OECD):\")\n",
        "    print(tabulate(top_features_comparison, headers='keys', tablefmt='simple'))\n",
        "\n",
        "    # Save comparison to file\n",
        "    with open('oecd_top_features_comparison.csv', 'w') as f:\n",
        "        f.write(tabulate(top_features_comparison, headers='keys', tablefmt='csv'))\n",
        "\n",
        "    # Compare SHAP values\n",
        "    common_features = set([item['Feature'] for item in oecd_results['shap_values'][:10]]).intersection(\n",
        "                      set([item['Feature'] for item in non_oecd_results['shap_values'][:10]]))\n",
        "\n",
        "    shap_comparison = []\n",
        "\n",
        "    for feature in common_features:\n",
        "        oecd_shap = next((item['Mean |SHAP Value|'] for item in oecd_results['shap_values'] if item['Feature'] == feature), 'N/A')\n",
        "        non_oecd_shap = next((item['Mean |SHAP Value|'] for item in non_oecd_results['shap_values'] if item['Feature'] == feature), 'N/A')\n",
        "\n",
        "        shap_comparison.append({\n",
        "            'Feature': feature,\n",
        "            'OECD Mean |SHAP|': oecd_shap,\n",
        "            'Non-OECD Mean |SHAP|': non_oecd_shap\n",
        "        })\n",
        "\n",
        "    print(\"\\n\\nSHAP Value Comparison for Common Top Features:\")\n",
        "    print(tabulate(shap_comparison, headers='keys', tablefmt='simple'))\n",
        "\n",
        "    # Save comparison to file\n",
        "    with open('oecd_shap_comparison.csv', 'w') as f:\n",
        "        f.write(tabulate(shap_comparison, headers='keys', tablefmt='csv'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBWhtjBloRPx",
        "outputId": "895c0bfc-e9df-423b-ee8f-e14c5a519a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "==================================================\n",
            "PART 1: OECD vs. NON-OECD ANALYSIS\n",
            "==================================================\n",
            "\n",
            "Running analysis for OECD countries...\n",
            "\n",
            "\n",
            "===== ANALYZING OECD Countries =====\n",
            "Number of schools in OECD Countries: 11108\n",
            "Schools with valid target in OECD Countries: 11108\n",
            "Training Random Forest model for OECD Countries...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed for OECD Countries\n",
            "Feature names extracted: 10 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OECD Countries - Mean Squared Error: 3633.59\n",
            "OECD Countries - R² Score: 0.1249\n",
            "OECD Countries - RMSE: 60.28\n",
            "\n",
            "OECD Countries Model Performance:\n",
            "Model                             Mean Squared Error    R² Score    RMSE    Sample Size\n",
            "------------------------------  --------------------  ----------  ------  -------------\n",
            "Random Forest (OECD Countries)               3633.59      0.1249   60.28           2222\n",
            "Feature importances extracted: 10 values\n",
            "\n",
            "OECD Countries Feature Importance:\n",
            "Feature             Importance  Cumulative %\n",
            "----------------  ------------  --------------\n",
            "Probscri                0.2206  22.06%\n",
            "Daysclosed covid        0.1761  39.67%\n",
            "Digprep                 0.1709  56.76%\n",
            "Scprepap                0.135   70.26%\n",
            "Scprepbp                0.094   79.66%\n",
            "Self study              0.064   86.05%\n",
            "Remote teaching         0.0538  91.43%\n",
            "Class cancelled         0.0493  96.36%\n",
            "Schltype 3              0.0293  99.29%\n",
            "Schltype 2              0.0071  100.00%\n",
            "\n",
            "Calculating SHAP values for OECD Countries...\n",
            "Sampling 2000 out of 2222 for SHAP analysis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHAP values calculated with shape: (2000, 10)\n",
            "\n",
            "OECD Countries SHAP Values:\n",
            "Feature             Mean |SHAP Value|    Min SHAP    Max SHAP\n",
            "----------------  -------------------  ----------  ----------\n",
            "Probscri                      11.8209    -75.0591     36.9863\n",
            "Schltype 3                     5.8123     -9.1932     36.0654\n",
            "Daysclosed covid               5.2419    -48.4809     23.2938\n",
            "Scprepap                       2.7151    -17.3783     15.5293\n",
            "Self study                     2.7103    -15.1077     20.8883\n",
            "Class cancelled                2.5778    -23.9575     11.718\n",
            "Digprep                        2.0388    -23.4904     10.6097\n",
            "Scprepbp                       1.4495    -12.2239     12.6026\n",
            "Remote teaching                1.3756    -31.2975     18.362\n",
            "Schltype 2                     1.1743    -11.3329     18.4727\n",
            "\n",
            "Running analysis for non-OECD countries...\n",
            "\n",
            "\n",
            "===== ANALYZING Non-OECD Countries =====\n",
            "Number of schools in Non-OECD Countries: 10521\n",
            "Schools with valid target in Non-OECD Countries: 10521\n",
            "Training Random Forest model for Non-OECD Countries...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed for Non-OECD Countries\n",
            "Feature names extracted: 10 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-OECD Countries - Mean Squared Error: 4120.96\n",
            "Non-OECD Countries - R² Score: 0.2038\n",
            "Non-OECD Countries - RMSE: 64.19\n",
            "\n",
            "Non-OECD Countries Model Performance:\n",
            "Model                                 Mean Squared Error    R² Score    RMSE    Sample Size\n",
            "----------------------------------  --------------------  ----------  ------  -------------\n",
            "Random Forest (Non-OECD Countries)               4120.96      0.2038   64.19           2105\n",
            "Feature importances extracted: 10 values\n",
            "\n",
            "Non-OECD Countries Feature Importance:\n",
            "Feature             Importance  Cumulative %\n",
            "----------------  ------------  --------------\n",
            "Probscri                0.2452  24.52%\n",
            "Digprep                 0.1448  38.99%\n",
            "Daysclosed covid        0.1387  52.87%\n",
            "Scprepap                0.1346  66.33%\n",
            "Schltype 3              0.0885  75.19%\n",
            "Scprepbp                0.0766  82.84%\n",
            "Class cancelled         0.0641  89.25%\n",
            "Self study              0.0583  95.08%\n",
            "Remote teaching         0.0418  99.26%\n",
            "Schltype 2              0.0074  100.00%\n",
            "\n",
            "Calculating SHAP values for Non-OECD Countries...\n",
            "Sampling 2000 out of 2105 for SHAP analysis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHAP values calculated with shape: (2000, 10)\n",
            "\n",
            "Non-OECD Countries SHAP Values:\n",
            "Feature             Mean |SHAP Value|    Min SHAP    Max SHAP\n",
            "----------------  -------------------  ----------  ----------\n",
            "Probscri                      14.7146    -47.3883     54.9427\n",
            "Schltype 3                    11.9114    -17.2083     56.7086\n",
            "Scprepap                       7.2645    -29.0301     24.6353\n",
            "Class cancelled                6.5094    -39.2935     19.5523\n",
            "Daysclosed covid               4.1982    -28.9257     29.8733\n",
            "Remote teaching                3.4903    -38.986       9.4508\n",
            "Self study                     3.2961    -18.1511     12.4242\n",
            "Digprep                        2.5202    -10.9673     28.4983\n",
            "Scprepbp                       1.9766    -10.094      15.0699\n",
            "Schltype 2                     0.2053     -5.8166     11.4557\n",
            "\n",
            "\n",
            "Comparison of OECD vs. Non-OECD Performance:\n",
            "Subset                  MSE      R²    RMSE    Sample Size\n",
            "------------------  -------  ------  ------  -------------\n",
            "OECD Countries      3633.59  0.1249   60.28           2222\n",
            "Non-OECD Countries  4120.96  0.2038   64.19           2105\n",
            "\n",
            "\n",
            "Top Features Comparison (OECD vs. Non-OECD):\n",
            "Subset              Top Feature 1    Top Feature 2     Top Feature 3     Top Feature 4    Top Feature 5\n",
            "------------------  ---------------  ----------------  ----------------  ---------------  ---------------\n",
            "OECD Countries      Probscri         Daysclosed covid  Digprep           Scprepap         Scprepbp\n",
            "Non-OECD Countries  Probscri         Digprep           Daysclosed covid  Scprepap         Schltype 3\n",
            "\n",
            "\n",
            "SHAP Value Comparison for Common Top Features:\n",
            "Feature             OECD Mean |SHAP|    Non-OECD Mean |SHAP|\n",
            "----------------  ------------------  ----------------------\n",
            "Probscri                     11.8209                 14.7146\n",
            "Remote teaching               1.3756                  3.4903\n",
            "Self study                    2.7103                  3.2961\n",
            "Schltype 2                    1.1743                  0.2053\n",
            "Schltype 3                    5.8123                 11.9114\n",
            "Class cancelled               2.5778                  6.5094\n",
            "Digprep                       2.0388                  2.5202\n",
            "Scprepbp                      1.4495                  1.9766\n",
            "Daysclosed covid              5.2419                  4.1982\n",
            "Scprepap                      2.7151                  7.2645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to analyze each school type subset (keeping OECD as a predictor)\n",
        "def analyze_school_type(data, schltype_value, subset_name):\n",
        "    print(f\"\\n\\n===== ANALYZING {subset_name} =====\")\n",
        "\n",
        "    # Filter data for the specific school type\n",
        "    subset_data = data[data['SCHLTYPE'] == schltype_value].copy()\n",
        "    print(f\"Number of schools in {subset_name}: {len(subset_data)}\")\n",
        "\n",
        "    # Handle missing data in target variable\n",
        "    subset_data = subset_data.dropna(subset=[target])\n",
        "    print(f\"Schools with valid target in {subset_name}: {len(subset_data)}\")\n",
        "\n",
        "    if len(subset_data) < 100:\n",
        "        print(f\"Not enough data for {subset_name} analysis.\")\n",
        "        return None\n",
        "\n",
        "    # Remove SCHLTYPE from features since we're analyzing by school type\n",
        "    # But keep OECD as a predictor\n",
        "    subset_features = [f for f in features if f != 'SCHLTYPE']\n",
        "\n",
        "    # Prepare X and y\n",
        "    X = subset_data[subset_features]\n",
        "    y = subset_data[target]\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create preprocessing pipeline with imputation\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', IterativeImputer(random_state=42), subset_features)\n",
        "        ])\n",
        "\n",
        "    # Create a pipeline with preprocessing and random forest\n",
        "    rf_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=500, max_depth=15, random_state=42, n_jobs=-1))\n",
        "    ])\n",
        "\n",
        "    # Fit the model\n",
        "    print(f\"Training Random Forest model for {subset_name}...\")\n",
        "    rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Get feature names\n",
        "    feature_names = subset_features\n",
        "\n",
        "    # Make predictions and evaluate the model\n",
        "    y_pred = rf_pipeline.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f\"{subset_name} - Mean Squared Error: {mse:.2f}\")\n",
        "    print(f\"{subset_name} - R² Score: {r2:.4f}\")\n",
        "    print(f\"{subset_name} - RMSE: {rmse:.2f}\")\n",
        "\n",
        "    # Create model performance table\n",
        "    model_performance = {\n",
        "        'Model': f\"Random Forest ({subset_name})\",\n",
        "        'Mean Squared Error': f'{mse:.2f}',\n",
        "        'R² Score': f'{r2:.4f}',\n",
        "        'RMSE': f'{rmse:.2f}',\n",
        "        'Sample Size': len(X_test)\n",
        "    }\n",
        "\n",
        "    # Print the table\n",
        "    print(f\"\\n{subset_name} Model Performance:\")\n",
        "    print(tabulate([model_performance], headers='keys', tablefmt='simple'))\n",
        "\n",
        "    # Get the RandomForest model from the pipeline\n",
        "    rf_model = rf_pipeline.named_steps['regressor']\n",
        "\n",
        "    # Get feature importances\n",
        "    importances = rf_model.feature_importances_\n",
        "\n",
        "    # Sort feature importances\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "    # Create a feature importance table\n",
        "    fi_table = []\n",
        "    cumulative = 0\n",
        "\n",
        "    for i in indices:\n",
        "        clean_name = feature_names[i].replace('_', ' ').capitalize()\n",
        "        cumulative += importances[i]\n",
        "        fi_table.append({\n",
        "            'Feature': clean_name,\n",
        "            'Importance': f'{importances[i]:.4f}',\n",
        "            'Cumulative %': f'{cumulative*100:.2f}%'\n",
        "        })\n",
        "\n",
        "    # Print the feature importance table\n",
        "    print(f\"\\n{subset_name} Feature Importance:\")\n",
        "    print(tabulate(fi_table, headers='keys', tablefmt='simple'))\n",
        "\n",
        "    # SHAP analysis\n",
        "    print(f\"\\nCalculating SHAP values for {subset_name}...\")\n",
        "\n",
        "    # Transform the test data\n",
        "    X_test_transformed = preprocessor.transform(X_test)\n",
        "\n",
        "    # Create an explainer\n",
        "    explainer = shap.TreeExplainer(rf_model)\n",
        "\n",
        "    # Calculate SHAP values\n",
        "    shap_values = explainer.shap_values(X_test_transformed)\n",
        "\n",
        "    # Create a SHAP values table\n",
        "    mean_abs_shap = np.abs(shap_values).mean(0)\n",
        "    top_indices = np.argsort(mean_abs_shap)[::-1]\n",
        "\n",
        "    shap_table = []\n",
        "    for i in top_indices:\n",
        "        clean_name = feature_names[i].replace('_', ' ').capitalize()\n",
        "        shap_table.append({\n",
        "            'Feature': clean_name,\n",
        "            'Mean |SHAP Value|': f'{mean_abs_shap[i]:.4f}',\n",
        "            'Min SHAP': f'{np.min(shap_values, axis=0)[i]:.4f}',\n",
        "            'Max SHAP': f'{np.max(shap_values, axis=0)[i]:.4f}'\n",
        "        })\n",
        "\n",
        "    # Print the SHAP values table\n",
        "    print(f\"\\n{subset_name} SHAP Values:\")\n",
        "    print(tabulate(shap_table[:10], headers='keys', tablefmt='simple'))\n",
        "\n",
        "    # Return the results\n",
        "    return {\n",
        "        'subset_name': subset_name,\n",
        "        'model_performance': model_performance,\n",
        "        'feature_importance': fi_table,\n",
        "        'shap_values': shap_table[:10],\n",
        "        'feature_names': feature_names,\n",
        "        'shap_vals': shap_values,\n",
        "        'X_test_transformed': X_test_transformed,\n",
        "        'explainer': explainer,\n",
        "        'rf_model': rf_model\n",
        "    }\n",
        "\n",
        "# Run analysis for each school type\n",
        "# Make sure to use integer values that match the data\n",
        "private_independent_results = analyze_school_type(data, 1, \"Private Independent Schools\")\n",
        "private_govt_dependent_results = analyze_school_type(data, 2, \"Private Government-Dependent Schools\")\n",
        "public_schools_results = analyze_school_type(data, 3, \"Public Schools\")\n",
        "\n",
        "# Collect all model performance results for comparison\n",
        "all_model_results = []\n",
        "for result in [\n",
        "    {'name': 'Full Dataset', 'mse': 3812.79, 'r2': 0.3772, 'rmse': 61.75, 'sample_size': 4326},\n",
        "    private_independent_results,\n",
        "    private_govt_dependent_results,\n",
        "    public_schools_results\n",
        "]:\n",
        "    if result:\n",
        "        if isinstance(result, dict) and 'model_performance' in result:\n",
        "            # Extract from results dictionary\n",
        "            perf = result['model_performance']\n",
        "            all_model_results.append({\n",
        "                'Subset': result['subset_name'],\n",
        "                'MSE': perf['Mean Squared Error'],\n",
        "                'R²': perf['R² Score'],\n",
        "                'RMSE': perf['RMSE'],\n",
        "                'Sample Size': perf['Sample Size']\n",
        "            })\n",
        "        else:\n",
        "            # Directly use provided dictionary\n",
        "            all_model_results.append({\n",
        "                'Subset': result['name'],\n",
        "                'MSE': f\"{result['mse']:.2f}\",\n",
        "                'R²': f\"{result['r2']:.4f}\",\n",
        "                'RMSE': f\"{result['rmse']:.2f}\",\n",
        "                'Sample Size': result['sample_size']\n",
        "            })\n",
        "\n",
        "# Print the comparative table\n",
        "print(\"\\n\\nComparative Model Performance Across School Types:\")\n",
        "print(tabulate(all_model_results, headers='keys', tablefmt='simple'))\n",
        "\n",
        "# If all analyses were successful, compare feature importance across school types\n",
        "if private_independent_results and private_govt_dependent_results and public_schools_results:\n",
        "    # Get top 5 features for each school type\n",
        "    feature_comparison = []\n",
        "\n",
        "    for result in [private_independent_results, private_govt_dependent_results, public_schools_results]:\n",
        "        top_features = []\n",
        "        for i, feature in enumerate(result['feature_importance']):\n",
        "            if i < 5:  # Top 5 features\n",
        "                top_features.append(feature['Feature'])\n",
        "        feature_comparison.append({\n",
        "            'School Type': result['subset_name'],\n",
        "            'Top Feature 1': top_features[0],\n",
        "            'Top Feature 2': top_features[1],\n",
        "            'Top Feature 3': top_features[2],\n",
        "            'Top Feature 4': top_features[3],\n",
        "            'Top Feature 5': top_features[4]\n",
        "        })\n",
        "\n",
        "    print(\"\\n\\nTop Features by School Type:\")\n",
        "    print(tabulate(feature_comparison, headers='keys', tablefmt='simple'))\n",
        "\n",
        "    # Create a comparison of OECD importance across school types\n",
        "    oecd_comparison = []\n",
        "\n",
        "    for result in [private_independent_results, private_govt_dependent_results, public_schools_results]:\n",
        "        # Find OECD in feature importance table\n",
        "        oecd_importance = '0.0000'\n",
        "        oecd_rank = 'Not Found'\n",
        "\n",
        "        for i, feature in enumerate(result['feature_importance']):\n",
        "            if feature['Feature'].lower() == 'oecd':\n",
        "                oecd_importance = feature['Importance']\n",
        "                oecd_rank = str(i + 1)\n",
        "                break\n",
        "\n",
        "        # Find OECD in SHAP values table\n",
        "        oecd_shap = '0.0000'\n",
        "        for feature in result['shap_values']:\n",
        "            if feature['Feature'].lower() == 'oecd':\n",
        "                oecd_shap = feature['Mean |SHAP Value|']\n",
        "                break\n",
        "\n",
        "        oecd_comparison.append({\n",
        "            'School Type': result['subset_name'],\n",
        "            'OECD Importance': oecd_importance,\n",
        "            'OECD Rank': oecd_rank,\n",
        "            'OECD Mean |SHAP|': oecd_shap\n",
        "        })\n",
        "\n",
        "    print(\"\\n\\nOECD Importance by School Type:\")\n",
        "    print(tabulate(oecd_comparison, headers='keys', tablefmt='simple'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86fwNRybBBOH",
        "outputId": "57a1cb86-9a49-4640-ac60-eb0477aceca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "===== ANALYZING Private Independent Schools =====\n",
            "Number of schools in Private Independent Schools: 0\n",
            "Schools with valid target in Private Independent Schools: 0\n",
            "Not enough data for Private Independent Schools analysis.\n",
            "\n",
            "\n",
            "===== ANALYZING Private Government-Dependent Schools =====\n",
            "Number of schools in Private Government-Dependent Schools: 0\n",
            "Schools with valid target in Private Government-Dependent Schools: 0\n",
            "Not enough data for Private Government-Dependent Schools analysis.\n",
            "\n",
            "\n",
            "===== ANALYZING Public Schools =====\n",
            "Number of schools in Public Schools: 0\n",
            "Schools with valid target in Public Schools: 0\n",
            "Not enough data for Public Schools analysis.\n",
            "\n",
            "\n",
            "Comparative Model Performance Across School Types:\n",
            "Subset            MSE      R²    RMSE    Sample Size\n",
            "------------  -------  ------  ------  -------------\n",
            "Full Dataset  3812.79  0.3772   61.75           4326\n"
          ]
        }
      ]
    }
  ]
}